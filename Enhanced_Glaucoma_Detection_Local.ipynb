{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhanced Glaucoma Detection with Custom Medical Imaging CNN (Local Version)\n",
    "This notebook implements a specialized CNN architecture for glaucoma detection with:\n",
    "- Custom multi-scale CNN with attention mechanisms\n",
    "- Advanced data augmentation\n",
    "- Class imbalance handling\n",
    "- Grad-CAM visualization\n",
    "- Comprehensive evaluation metrics\n",
    "\n",
    "**This version runs locally on your machine (no Google Colab required)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (run once)\n",
    "# !pip install tensorflow tensorflow-addons scikit-learn matplotlib seaborn opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import (\n",
    "    EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, \n",
    "    TensorBoard, CSVLogger\n",
    ")\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, classification_report, \n",
    "    roc_curve, auc, roc_auc_score,\n",
    "    precision_recall_curve, average_precision_score\n",
    ")\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import cv2\n",
    "import os\n",
    "from datetime import datetime\n",
    "import glob\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")\n",
    "print(f\"Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration - LOCAL PATHS\n",
    "BASE_PATH = r'c:\\Users\\likit\\OneDrive\\Documents\\projects\\glucamo'\n",
    "\n",
    "TRAINING_PATH = os.path.join(BASE_PATH, 'Train-20251107T233046Z-1-001', 'Train')\n",
    "VALIDATION_PATH = os.path.join(BASE_PATH, 'Validation-20251107T232720Z-1-001', 'Validation')\n",
    "TEST_PATH = os.path.join(BASE_PATH, 'Test-20251108T015821Z-1-001', 'Test')\n",
    "\n",
    "# Verify paths exist\n",
    "print(\"Checking data paths...\")\n",
    "print(f\"Training path exists: {os.path.exists(TRAINING_PATH)}\")\n",
    "print(f\"Validation path exists: {os.path.exists(VALIDATION_PATH)}\")\n",
    "print(f\"Test path exists: {os.path.exists(TEST_PATH)}\")\n",
    "\n",
    "if not os.path.exists(TRAINING_PATH):\n",
    "    print(f\"\\n⚠️ WARNING: Training path not found: {TRAINING_PATH}\")\n",
    "    print(\"Please verify your data folder structure.\")\n",
    "\n",
    "# Model configuration\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "NUM_CLASSES = 2\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# Model save path (local)\n",
    "MODEL_NAME = f'glaucoma_custom_cnn_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}'\n",
    "CHECKPOINT_PATH = os.path.join(BASE_PATH, 'checkpoints', MODEL_NAME)\n",
    "os.makedirs(CHECKPOINT_PATH, exist_ok=True)\n",
    "\n",
    "print(f\"\\nModels will be saved to: {CHECKPOINT_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom CNN Architecture Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Squeeze-and-Excitation Block for Attention\n",
    "class SEBlock(layers.Layer):\n",
    "    def __init__(self, filters, ratio=16, **kwargs):\n",
    "        super(SEBlock, self).__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        self.ratio = ratio\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.global_pool = layers.GlobalAveragePooling2D()\n",
    "        self.dense1 = layers.Dense(self.filters // self.ratio, activation='relu')\n",
    "        self.dense2 = layers.Dense(self.filters, activation='sigmoid')\n",
    "        self.reshape = layers.Reshape((1, 1, self.filters))\n",
    "        self.multiply = layers.Multiply()\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        se = self.global_pool(inputs)\n",
    "        se = self.dense1(se)\n",
    "        se = self.dense2(se)\n",
    "        se = self.reshape(se)\n",
    "        return self.multiply([inputs, se])\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"filters\": self.filters, \"ratio\": self.ratio})\n",
    "        return config\n",
    "\n",
    "\n",
    "# Residual Block with SE attention\n",
    "def residual_block_with_se(x, filters, kernel_size=3, stride=1, use_se=True):\n",
    "    \"\"\"Residual block with optional Squeeze-and-Excitation\"\"\"\n",
    "    shortcut = x\n",
    "    \n",
    "    # Main path\n",
    "    x = layers.Conv2D(filters, kernel_size, strides=stride, padding='same',\n",
    "                     kernel_initializer='he_normal')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    x = layers.Conv2D(filters, kernel_size, strides=1, padding='same',\n",
    "                     kernel_initializer='he_normal')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    # SE block\n",
    "    if use_se:\n",
    "        x = SEBlock(filters)(x)\n",
    "    \n",
    "    # Shortcut connection\n",
    "    if stride != 1 or shortcut.shape[-1] != filters:\n",
    "        shortcut = layers.Conv2D(filters, 1, strides=stride, padding='same')(shortcut)\n",
    "        shortcut = layers.BatchNormalization()(shortcut)\n",
    "    \n",
    "    x = layers.Add()([x, shortcut])\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "# Multi-scale Inception-like block\n",
    "def inception_block(x, filters):\n",
    "    \"\"\"Multi-scale feature extraction\"\"\"\n",
    "    # 1x1 conv\n",
    "    branch1 = layers.Conv2D(filters, 1, padding='same', activation='relu',\n",
    "                           kernel_initializer='he_normal')(x)\n",
    "    \n",
    "    # 3x3 conv\n",
    "    branch2 = layers.Conv2D(filters, 1, padding='same', activation='relu',\n",
    "                           kernel_initializer='he_normal')(x)\n",
    "    branch2 = layers.Conv2D(filters, 3, padding='same', activation='relu',\n",
    "                           kernel_initializer='he_normal')(branch2)\n",
    "    \n",
    "    # 5x5 conv (using two 3x3 for efficiency)\n",
    "    branch3 = layers.Conv2D(filters, 1, padding='same', activation='relu',\n",
    "                           kernel_initializer='he_normal')(x)\n",
    "    branch3 = layers.Conv2D(filters, 3, padding='same', activation='relu',\n",
    "                           kernel_initializer='he_normal')(branch3)\n",
    "    branch3 = layers.Conv2D(filters, 3, padding='same', activation='relu',\n",
    "                           kernel_initializer='he_normal')(branch3)\n",
    "    \n",
    "    # Max pooling branch\n",
    "    branch4 = layers.MaxPooling2D(3, strides=1, padding='same')(x)\n",
    "    branch4 = layers.Conv2D(filters, 1, padding='same', activation='relu',\n",
    "                           kernel_initializer='he_normal')(branch4)\n",
    "    \n",
    "    # Concatenate all branches\n",
    "    output = layers.Concatenate()([branch1, branch2, branch3, branch4])\n",
    "    output = layers.BatchNormalization()(output)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Custom Medical Imaging CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_custom_medical_cnn(input_shape=(224, 224, 3), num_classes=2):\n",
    "    \"\"\"\n",
    "    Custom CNN architecture for medical imaging with:\n",
    "    - Multi-scale feature extraction\n",
    "    - Attention mechanisms (SE blocks)\n",
    "    - Residual connections\n",
    "    - Dropout for regularization\n",
    "    \"\"\"\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # Initial convolution\n",
    "    x = layers.Conv2D(64, 7, strides=2, padding='same', \n",
    "                     kernel_initializer='he_normal')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.MaxPooling2D(3, strides=2, padding='same')(x)\n",
    "    \n",
    "    # Stage 1: Residual blocks with SE\n",
    "    x = residual_block_with_se(x, 64, use_se=True)\n",
    "    x = residual_block_with_se(x, 64, use_se=True)\n",
    "    \n",
    "    # Stage 2: Multi-scale inception block + residual\n",
    "    x = inception_block(x, 32)  # Output: 128 filters (4 branches * 32)\n",
    "    x = layers.MaxPooling2D(2, strides=2)(x)\n",
    "    x = residual_block_with_se(x, 128, use_se=True)\n",
    "    x = residual_block_with_se(x, 128, use_se=True)\n",
    "    \n",
    "    # Stage 3: Deeper features\n",
    "    x = residual_block_with_se(x, 256, stride=2, use_se=True)\n",
    "    x = residual_block_with_se(x, 256, use_se=True)\n",
    "    x = residual_block_with_se(x, 256, use_se=True)\n",
    "    \n",
    "    # Stage 4: High-level features\n",
    "    x = inception_block(x, 64)  # Output: 256 filters\n",
    "    x = layers.MaxPooling2D(2, strides=2)(x)\n",
    "    x = residual_block_with_se(x, 512, use_se=True)\n",
    "    x = residual_block_with_se(x, 512, use_se=True)\n",
    "    \n",
    "    # Global pooling and dense layers\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    \n",
    "    # Dense layers with batch normalization\n",
    "    x = layers.Dense(512, kernel_initializer='he_normal')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    \n",
    "    x = layers.Dense(256, kernel_initializer='he_normal')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    \n",
    "    # Output layer\n",
    "    outputs = layers.Dense(num_classes, activation='softmax', \n",
    "                          kernel_initializer='glorot_uniform')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs, name='MedicalImageCNN')\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# Build the model\n",
    "print(\"Building custom medical imaging CNN...\")\n",
    "model = build_custom_medical_cnn(input_shape=(224, 224, 3), num_classes=NUM_CLASSES)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Data Augmentation for Medical Imaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Medical image augmentation\n",
    "print(\"Setting up data generators...\")\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    fill_mode='reflect'\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Load training data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAINING_PATH,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Load validation data\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    VALIDATION_PATH,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Load test data (if available)\n",
    "if os.path.exists(TEST_PATH):\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        TEST_PATH,\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False,\n",
    "        seed=42\n",
    "    )\n",
    "    print(f\"Test samples: {test_generator.n}\")\n",
    "\n",
    "print(f\"Training samples: {train_generator.n}\")\n",
    "print(f\"Validation samples: {validation_generator.n}\")\n",
    "print(f\"Class indices: {train_generator.class_indices}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate class weights to handle imbalance\n",
    "class_counts = np.bincount(train_generator.classes)\n",
    "print(f\"Class distribution: {class_counts}\")\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_generator.classes),\n",
    "    y=train_generator.classes\n",
    ")\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "print(f\"Class weights: {class_weight_dict}\")\n",
    "\n",
    "# Visualize class distribution\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(['Class 0 (Normal)', 'Class 1 (Glaucoma)'], class_counts, \n",
    "        color=['green', 'red'], alpha=0.7)\n",
    "plt.title('Training Data Class Distribution')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.xlabel('Classes')\n",
    "for i, count in enumerate(class_counts):\n",
    "    plt.text(i, count, str(count), ha='center', va='bottom')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(CHECKPOINT_PATH, 'class_distribution.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Focal Loss for Imbalanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focal Loss implementation\n",
    "class FocalLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, gamma=2.0, alpha=0.25, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def call(self, y_true, y_pred):\n",
    "        epsilon = tf.keras.backend.epsilon()\n",
    "        y_pred = tf.clip_by_value(y_pred, epsilon, 1.0 - epsilon)\n",
    "        \n",
    "        # Calculate focal loss\n",
    "        cross_entropy = -y_true * tf.math.log(y_pred)\n",
    "        weight = self.alpha * y_true * tf.math.pow(1 - y_pred, self.gamma)\n",
    "        \n",
    "        loss = weight * cross_entropy\n",
    "        return tf.reduce_sum(loss, axis=-1)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"gamma\": self.gamma, \"alpha\": self.alpha})\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile Model with Advanced Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Focal Loss or standard categorical crossentropy\n",
    "USE_FOCAL_LOSS = True\n",
    "\n",
    "if USE_FOCAL_LOSS:\n",
    "    loss = FocalLoss(gamma=2.0, alpha=0.25)\n",
    "    print(\"Using Focal Loss\")\n",
    "else:\n",
    "    loss = 'categorical_crossentropy'\n",
    "    print(\"Using Categorical Crossentropy\")\n",
    "\n",
    "# Use AdamW optimizer with weight decay\n",
    "optimizer = tfa.optimizers.AdamW(\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=1e-4\n",
    ")\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss,\n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall'),\n",
    "        tf.keras.metrics.AUC(name='auc'),\n",
    "        tfa.metrics.F1Score(num_classes=NUM_CLASSES, average='macro', name='f1_score')\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Model compiled successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "callbacks = [\n",
    "    # Early stopping\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=15,\n",
    "        verbose=1,\n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "    \n",
    "    # Model checkpoint - save best model\n",
    "    ModelCheckpoint(\n",
    "        filepath=os.path.join(CHECKPOINT_PATH, 'best_model.keras'),\n",
    "        monitor='val_auc',\n",
    "        mode='max',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    # Reduce learning rate on plateau\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    # TensorBoard logging\n",
    "    TensorBoard(\n",
    "        log_dir=os.path.join(CHECKPOINT_PATH, 'logs'),\n",
    "        histogram_freq=1,\n",
    "        write_graph=True\n",
    "    ),\n",
    "    \n",
    "    # CSV logger\n",
    "    CSVLogger(\n",
    "        os.path.join(CHECKPOINT_PATH, 'training_log.csv'),\n",
    "        append=False\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"Callbacks configured successfully!\")\n",
    "print(f\"\\nTo monitor training in TensorBoard, run:\")\n",
    "print(f\"tensorboard --logdir=\\\"{os.path.join(CHECKPOINT_PATH, 'logs')}\\\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "print(\"\\nStarting training...\")\n",
    "print(f\"Epochs: {EPOCHS}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Learning rate: {LEARNING_RATE}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    class_weight=class_weight_dict if not USE_FOCAL_LOSS else None,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nTraining completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history, save_path):\n",
    "    \"\"\"Plot training and validation metrics\"\"\"\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "    fig.suptitle('Training History', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    metrics = [\n",
    "        ('loss', 'Loss'),\n",
    "        ('accuracy', 'Accuracy'),\n",
    "        ('precision', 'Precision'),\n",
    "        ('recall', 'Recall'),\n",
    "        ('auc', 'AUC'),\n",
    "        ('f1_score', 'F1 Score')\n",
    "    ]\n",
    "    \n",
    "    for idx, (metric, title) in enumerate(metrics):\n",
    "        ax = axes[idx // 3, idx % 3]\n",
    "        \n",
    "        if metric in history.history:\n",
    "            ax.plot(history.history[metric], label=f'Train {title}', linewidth=2)\n",
    "            ax.plot(history.history[f'val_{metric}'], label=f'Val {title}', linewidth=2)\n",
    "            ax.set_xlabel('Epoch', fontsize=10)\n",
    "            ax.set_ylabel(title, fontsize=10)\n",
    "            ax.set_title(f'{title} Over Epochs', fontweight='bold')\n",
    "            ax.legend(loc='best')\n",
    "            ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_path, 'training_history.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(history, CHECKPOINT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions on validation set\n",
    "print(\"Generating predictions on validation set...\")\n",
    "validation_generator.reset()\n",
    "y_true = validation_generator.classes\n",
    "y_pred_probs = model.predict(validation_generator, verbose=1)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "print(\"Predictions completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "def plot_confusion_matrix(y_true, y_pred, labels, save_path):\n",
    "    cm = confusion_matrix(y_true, y_pred, normalize='true')\n",
    "    cm_percentage = cm * 100\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm_percentage, annot=True, fmt='.2f', cmap='Blues',\n",
    "                xticklabels=labels, yticklabels=labels,\n",
    "                cbar_kws={'label': 'Percentage'})\n",
    "    plt.title('Normalized Confusion Matrix (%)', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('True Label', fontsize=12)\n",
    "    plt.xlabel('Predicted Label', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_path, 'confusion_matrix.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Also show counts\n",
    "    cm_counts = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm_counts, annot=True, fmt='d', cmap='Greens',\n",
    "                xticklabels=labels, yticklabels=labels,\n",
    "                cbar_kws={'label': 'Count'})\n",
    "    plt.title('Confusion Matrix (Counts)', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('True Label', fontsize=12)\n",
    "    plt.xlabel('Predicted Label', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_path, 'confusion_matrix_counts.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "class_labels = ['Normal', 'Glaucoma']\n",
    "plot_confusion_matrix(y_true, y_pred, class_labels, CHECKPOINT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(y_true, y_pred, target_names=class_labels, digits=4))\n",
    "\n",
    "# Save report to file\n",
    "with open(os.path.join(CHECKPOINT_PATH, 'classification_report.txt'), 'w') as f:\n",
    "    f.write(classification_report(y_true, y_pred, target_names=class_labels, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC-AUC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(y_true, y_pred_probs, class_labels, save_path):\n",
    "    \"\"\"Plot ROC curve for each class\"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # For binary classification, plot for positive class\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred_probs[:, 1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, \n",
    "             label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Classifier')\n",
    "    \n",
    "    # Find optimal threshold (Youden's J statistic)\n",
    "    J = tpr - fpr\n",
    "    ix = np.argmax(J)\n",
    "    best_thresh = thresholds[ix]\n",
    "    plt.scatter(fpr[ix], tpr[ix], marker='o', color='red', s=200, \n",
    "                label=f'Optimal Threshold = {best_thresh:.3f}')\n",
    "    \n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate', fontsize=12)\n",
    "    plt.ylabel('True Positive Rate (Sensitivity)', fontsize=12)\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve', fontsize=14, fontweight='bold')\n",
    "    plt.legend(loc=\"lower right\", fontsize=10)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_path, 'roc_curve.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nOptimal Threshold: {best_thresh:.4f}\")\n",
    "    print(f\"Sensitivity at optimal threshold: {tpr[ix]:.4f}\")\n",
    "    print(f\"Specificity at optimal threshold: {1-fpr[ix]:.4f}\")\n",
    "    \n",
    "    return best_thresh\n",
    "\n",
    "optimal_threshold = plot_roc_curve(y_true, y_pred_probs, class_labels, CHECKPOINT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision-Recall Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precision_recall_curve(y_true, y_pred_probs, save_path):\n",
    "    \"\"\"Plot Precision-Recall curve\"\"\"\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, y_pred_probs[:, 1])\n",
    "    avg_precision = average_precision_score(y_true, y_pred_probs[:, 1])\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.plot(recall, precision, color='blue', lw=2,\n",
    "             label=f'Precision-Recall curve (AP = {avg_precision:.4f})')\n",
    "    \n",
    "    # F1 score iso-lines\n",
    "    f_scores = np.linspace(0.2, 0.9, num=8)\n",
    "    for f_score in f_scores:\n",
    "        x = np.linspace(0.01, 1)\n",
    "        y = f_score * x / (2 * x - f_score)\n",
    "        plt.plot(x[y >= 0], y[y >= 0], color='gray', alpha=0.3, linestyle='--')\n",
    "        plt.annotate(f'F1={f_score:.1f}', xy=(0.9, y[45] + 0.02), alpha=0.4, fontsize=8)\n",
    "    \n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('Recall (Sensitivity)', fontsize=12)\n",
    "    plt.ylabel('Precision', fontsize=12)\n",
    "    plt.title('Precision-Recall Curve', fontsize=14, fontweight='bold')\n",
    "    plt.legend(loc=\"lower left\", fontsize=10)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_path, 'precision_recall_curve.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "plot_precision_recall_curve(y_true, y_pred_probs, CHECKPOINT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grad-CAM Visualization for Interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    \"\"\"Generate Grad-CAM heatmap\"\"\"\n",
    "    grad_model = Model(\n",
    "        inputs=[model.inputs],\n",
    "        outputs=[model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(predictions[0])\n",
    "        class_channel = predictions[:, pred_index]\n",
    "    \n",
    "    grads = tape.gradient(class_channel, conv_outputs)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "    \n",
    "    conv_outputs = conv_outputs[0]\n",
    "    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "    \n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()\n",
    "\n",
    "\n",
    "def display_gradcam(img_path, model, last_conv_layer_name, alpha=0.4):\n",
    "    \"\"\"Display Grad-CAM visualization\"\"\"\n",
    "    img = tf.keras.preprocessing.image.load_img(img_path, target_size=IMG_SIZE)\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0) / 255.0\n",
    "    \n",
    "    preds = model.predict(img_array, verbose=0)\n",
    "    pred_class = np.argmax(preds[0])\n",
    "    pred_prob = preds[0][pred_class]\n",
    "    \n",
    "    heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n",
    "    \n",
    "    heatmap = cv2.resize(heatmap, (img.size[0], img.size[1]))\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "    \n",
    "    img_array_uint8 = np.uint8(255 * img_array[0])\n",
    "    superimposed_img = cv2.addWeighted(img_array_uint8, 1-alpha, heatmap, alpha, 0)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    axes[0].imshow(img)\n",
    "    axes[0].set_title('Original Image', fontweight='bold')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].imshow(heatmap)\n",
    "    axes[1].set_title('Grad-CAM Heatmap', fontweight='bold')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    axes[2].imshow(superimposed_img)\n",
    "    axes[2].set_title(f'Superimposed\\nPrediction: {class_labels[pred_class]} ({pred_prob:.2%})', \n",
    "                     fontweight='bold')\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return pred_class, pred_prob\n",
    "\n",
    "\n",
    "# Find the last convolutional layer\n",
    "last_conv_layer = None\n",
    "for layer in reversed(model.layers):\n",
    "    if isinstance(layer, layers.Conv2D):\n",
    "        last_conv_layer = layer.name\n",
    "        break\n",
    "\n",
    "print(f\"Last convolutional layer: {last_conv_layer}\")\n",
    "print(\"\\nReady to visualize Grad-CAM!\")\n",
    "print(\"Use: display_gradcam('path/to/image.png', model, last_conv_layer)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Visualize Grad-CAM for sample images\n",
    "print(\"Generating Grad-CAM visualizations...\")\n",
    "\n",
    "# Get sample images from validation set\n",
    "normal_images = glob.glob(os.path.join(VALIDATION_PATH, '0', '*.png'))[:5]\n",
    "glaucoma_images = glob.glob(os.path.join(VALIDATION_PATH, '1', '*.png'))[:5]\n",
    "\n",
    "if len(normal_images) > 0:\n",
    "    print(\"\\nGrad-CAM Visualization for Normal Cases:\")\n",
    "    print(\"=\"*60)\n",
    "    for img_path in normal_images[:2]:  # Show 2 examples\n",
    "        print(f\"\\nImage: {os.path.basename(img_path)}\")\n",
    "        display_gradcam(img_path, model, last_conv_layer)\n",
    "\n",
    "if len(glaucoma_images) > 0:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Grad-CAM Visualization for Glaucoma Cases:\")\n",
    "    print(\"=\"*60)\n",
    "    for img_path in glaucoma_images[:2]:  # Show 2 examples\n",
    "        print(f\"\\nImage: {os.path.basename(img_path)}\")\n",
    "        display_gradcam(img_path, model, last_conv_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save in multiple formats\n",
    "print(\"\\nSaving models...\")\n",
    "\n",
    "# 1. Native Keras format (recommended)\n",
    "model.save(os.path.join(CHECKPOINT_PATH, 'final_model.keras'))\n",
    "print(\"✓ Model saved in Keras format (.keras)\")\n",
    "\n",
    "# 2. H5 format for compatibility\n",
    "model.save(os.path.join(CHECKPOINT_PATH, 'final_model.h5'))\n",
    "print(\"✓ Model saved in H5 format (.h5)\")\n",
    "\n",
    "# 3. TensorFlow Lite for mobile deployment\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open(os.path.join(CHECKPOINT_PATH, 'final_model.tflite'), 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "print(\"✓ Model saved in TFLite format (.tflite)\")\n",
    "\n",
    "# 4. SavedModel format for TensorFlow Serving\n",
    "model.save(os.path.join(CHECKPOINT_PATH, 'saved_model'), save_format='tf')\n",
    "print(\"✓ Model saved in SavedModel format\")\n",
    "\n",
    "print(f\"\\n✓ All models saved to: {CHECKPOINT_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print final summary\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nModel Architecture: Custom Medical Imaging CNN\")\n",
    "print(f\"Total Parameters: {model.count_params():,}\")\n",
    "print(f\"Training Samples: {train_generator.n}\")\n",
    "print(f\"Validation Samples: {validation_generator.n}\")\n",
    "print(f\"Epochs Trained: {len(history.history['loss'])}\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"BEST VALIDATION METRICS\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "metrics_to_show = ['val_accuracy', 'val_precision', 'val_recall', 'val_auc', 'val_f1_score']\n",
    "for metric in metrics_to_show:\n",
    "    if metric in history.history:\n",
    "        best_value = max(history.history[metric])\n",
    "        best_epoch = np.argmax(history.history[metric]) + 1\n",
    "        print(f\"{metric.replace('val_', '').upper():.<30} {best_value:.4f} (Epoch {best_epoch})\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"VALIDATION SET PERFORMANCE\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, average='binary')\n",
    "recall = recall_score(y_true, y_pred, average='binary')\n",
    "f1 = f1_score(y_true, y_pred, average='binary')\n",
    "roc_auc = roc_auc_score(y_true, y_pred_probs[:, 1])\n",
    "\n",
    "print(f\"{'Accuracy':.<30} {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"{'Precision':.<30} {precision:.4f}\")\n",
    "print(f\"{'Recall (Sensitivity)':.<30} {recall:.4f}\")\n",
    "print(f\"{'F1 Score':.<30} {f1:.4f}\")\n",
    "print(f\"{'ROC-AUC':.<30} {roc_auc:.4f}\")\n",
    "\n",
    "# Calculate specificity\n",
    "tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "print(f\"{'Specificity':.<30} {specificity:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"Models saved to: {CHECKPOINT_PATH}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Save summary to text file\n",
    "with open(os.path.join(CHECKPOINT_PATH, 'training_summary.txt'), 'w') as f:\n",
    "    f.write(\"TRAINING SUMMARY\\n\")\n",
    "    f.write(\"=\"*80 + \"\\n\\n\")\n",
    "    f.write(f\"Model: Custom Medical Imaging CNN\\n\")\n",
    "    f.write(f\"Parameters: {model.count_params():,}\\n\")\n",
    "    f.write(f\"Training Samples: {train_generator.n}\\n\")\n",
    "    f.write(f\"Validation Samples: {validation_generator.n}\\n\")\n",
    "    f.write(f\"Epochs: {len(history.history['loss'])}\\n\\n\")\n",
    "    f.write(f\"Accuracy: {accuracy:.4f}\\n\")\n",
    "    f.write(f\"Precision: {precision:.4f}\\n\")\n",
    "    f.write(f\"Recall: {recall:.4f}\\n\")\n",
    "    f.write(f\"F1 Score: {f1:.4f}\\n\")\n",
    "    f.write(f\"ROC-AUC: {roc_auc:.4f}\\n\")\n",
    "    f.write(f\"Specificity: {specificity:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Image Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single_image(image_path, model, show_gradcam=True):\n",
    "    \"\"\"\n",
    "    Predict a single image and optionally show Grad-CAM\n",
    "    \"\"\"\n",
    "    img = tf.keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0) / 255.0\n",
    "    \n",
    "    prediction = model.predict(img_array, verbose=0)\n",
    "    pred_class = np.argmax(prediction[0])\n",
    "    pred_prob = prediction[0][pred_class]\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"PREDICTION RESULT\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Image: {os.path.basename(image_path)}\")\n",
    "    print(f\"Predicted Class: {class_labels[pred_class]}\")\n",
    "    print(f\"Confidence: {pred_prob:.2%}\")\n",
    "    print(f\"\\nClass Probabilities:\")\n",
    "    for i, label in enumerate(class_labels):\n",
    "        print(f\"  {label}: {prediction[0][i]:.2%}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if show_gradcam:\n",
    "        display_gradcam(image_path, model, last_conv_layer)\n",
    "    else:\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.imshow(img)\n",
    "        plt.title(f'{class_labels[pred_class]} ({pred_prob:.2%})', fontweight='bold')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    \n",
    "    return pred_class, pred_prob\n",
    "\n",
    "\n",
    "print(\"\\nReady to predict!\")\n",
    "print(\"\\nExample usage:\")\n",
    "print(\"predict_single_image(r'c:\\\\path\\\\to\\\\your\\\\image.png', model, show_gradcam=True)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open Results Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the checkpoint folder in Windows Explorer\n",
    "import subprocess\n",
    "\n",
    "print(f\"\\nOpening results folder: {CHECKPOINT_PATH}\")\n",
    "subprocess.Popen(f'explorer \"{CHECKPOINT_PATH}\"')\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nAll results saved to: {CHECKPOINT_PATH}\")\n",
    "print(\"\\nGenerated files:\")\n",
    "print(\"  - best_model.keras (best model during training)\")\n",
    "print(\"  - final_model.keras (final model)\")\n",
    "print(\"  - final_model.h5 (H5 format)\")\n",
    "print(\"  - final_model.tflite (mobile deployment)\")\n",
    "print(\"  - saved_model/ (TensorFlow Serving)\")\n",
    "print(\"  - training_log.csv (detailed metrics)\")\n",
    "print(\"  - training_history.png\")\n",
    "print(\"  - confusion_matrix.png\")\n",
    "print(\"  - roc_curve.png\")\n",
    "print(\"  - precision_recall_curve.png\")\n",
    "print(\"  - classification_report.txt\")\n",
    "print(\"  - training_summary.txt\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
